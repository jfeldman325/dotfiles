op() {
 local cmd="$1"
 [ $# -ge 1 ] && shift || true
 if [ x"$cmd" = x"signin" ] && [ $# -eq 0 ]; then
  eval $(_lc_op_run signin)
  env | grep "OP_SESSION" >> ~/.zshenv
 elif [ x"$cmd" = x"signout" ] && [ $# -eq 0 ]; then
  _lc_op_run "$cmd" "$@" && unset BW_SESSION
 else
  _lc_op_run "$cmd" "$@"
 fi
}

_lc_op_run() {
 local cmd="$1"
 [ $# -ge 1 ] && shift || true
 if [ x"$cmd" != x"" ]; then
  command op "$cmd" "$@"
 else
  command op "$@"
 fi
}

bw() {
 local cmd="$1"
 [ $# -ge 1 ] && shift || true
 if [ x"$cmd" = x"unlock" ] && [ $# -eq 0 ]; then
  local session="$(FORCE_COLOR=$(_bw_force_color) _bw_run "$cmd" --raw "$@")"
  export BW_SESSION=$session
  echo "export BW_SESSION=$session" >> ~/.zshenv
 elif [ x"$cmd" = x"lock" ] && [ $# -eq 0 ]; then
  _bw_run "$cmd" "$@" && unset BW_SESSION
 else
  _bw_run "$cmd" "$@"
 fi
}



_bw_run() {
 local cmd="$1"
 [ $# -ge 1 ] && shift || true
 if [ x"$cmd" != x"" ]; then
  command bw "$cmd" "$@"
 else
  command bw "$@"
 fi
}


_bw_force_color() {
 # Determine the value of $FORCE_COLOR for <https://www.npmjs.com/package/chalk>.
 
 if [ x"$FORCE_COLOR" != x"" ]; then
  # $FORCE_COLOR is already set
  echo "$FORCE_COLOR"
 elif ! [ -t 0 ]; then
  # stdin is not a TTY
  echo 0
 elif ([ x"$COLORTERM" = x"truecolor" ] || [ x"$COLORTERM" = x"24bit" ]) \
    && [ x"$STY" = x"" ]; then
  # true color
  echo 3
 elif (printf '%s\n' "$TERM" | grep -q -e '256') && [ x"$PS1_COLOR_256" != x"" ]; then
  # 256 colors
  echo 2
 else
  # assume color is supported
  echo 1
 fi
}

alias gpu-nodes-by-dc="kubecolor get nodes -l node.coreweave.cloud/class=gpu \
  -o=jsonpath='{range .items[*]}{.metadata.labels.gpu\.nvidia\.com\/model} {.status.allocatable.nvidia\.com\/gpu} {.status.capacity.nvidia\.com\/gpu} {.metadata.labels.topology\.kubernetes\.io\/region} {.status.conditions[?(@.type==\"Ready\")].status} {.spec.taints[?(@.key==\"node.coreweave.cloud/hypervisor\")].value}{\"\n\"}{end}' \
  | awk '{
          if(\$5 == \"True\") {
            if(\$6 == \"true\") {
              gpuVirt[\$4, \$1] += \$2
            }
            gpuAvail[\$4, \$1] += \$2;
            regions[\$4]; gpus[\$1]}
          }END{
            for (r in regions) {
              if(r != \"\") {
                printf \"\033[32mRegion: %s\033[0m\n\", r;
                printf \"-\t %s %s %s\n\", \"GPU\", \"Count\", \"Virtualized\";
                for (g in gpus) {
                  if(gpuAvail[r, g] != \"\") {
                    printf \"\033[34m-\t %s %s %s\033[0m\n\", g, gpuAvail[r, g], (gpuVirt[r, g] + 0)
                  }
                }
              }
            }
          }'\
  | column -t"

kcopy() {
  read -d '' manifest
  remove_ann=false
  name=""
  while [[ ! -z $1 ]]; do
    case "$1" in
      "-a"|"--remove-annotations")
        remove_ann=true
        ;;
      "-n"|"--replace-name")
        shift
        name=$1
        ;;
    esac
    shift
  done
  manifest=$(echo "$manifest" | kneat | yq e 'del(.metadata.namespace)' - | yq e 'del(.spec.volumeName)' - | yq e 'del(.spec.clusterIP)' - | yq e 'del(.spec.ports[].nodePort)' -)
  echo $manifest
  if [[ $remove_ann ]]; then
    manifest=$(echo "$manifest" | yq e 'del(.metadata.annotations)' -)
  fi
  if [[ ! -z $name ]]; then
    manifest=$(echo "$manifest" | yq e ".metadata.name = \"$name\"" -)
  fi
  echo "$manifest" | k apply -f -
}

hid(){
  helm install $1 ~/Coreweave/deadline/helm/deadline -f ~/Coreweave/deadline/helm/value-variants/$2/$2-setup.yaml -f ~/Coreweave/deadline/helm/value-variants/$2/$2-scale.yaml -f ~/Coreweave/deadline/helm/value-variants/$2/$2-workers.yaml
}
hud(){
  emc $(kgn) $1 && helm upgrade $1 ~/Coreweave/deadline/helm/deadline -f ~/Coreweave/deadline/helm/value-variants/$2/$2-setup.yaml -f ~/Coreweave/deadline/helm/value-variants/$2/$2-scale.yaml -f ~/Coreweave/deadline/helm/value-variants/$2/$2-workers.yaml --set mongodb.auth.rootPassword=$MONGODB_ROOT_PASSWORD --set mongodb.auth.replicaSetKey=$MONGODB_REPLICA_SET_KEY
}

hdud(){
  emc $(kgn) $1 && helm diff upgrade --debug $1 ~/Coreweave/deadline/helm/deadline -f ~/Coreweave/deadline/helm/value-variants/$2/$2-setup.yaml -f ~/Coreweave/deadline/helm/value-variants/$2/$2-scale.yaml -f ~/Coreweave/deadline/helm/value-variants/$2/$2-workers.yaml --set mongodb.auth.rootPassword=$MONGODB_ROOT_PASSWORD --set mongodb.auth.replicaSetKey=$MONGODB_REPLICA_SET_KEY
}
kgn(){
  kubecolor config view --minify --output 'jsonpath={..namespace}'; echo
}
kubes(){
  kubens $1 && emc $1
}
htd(){
  emc $(kgn) $1 && helm template --debug $1 ~/Coreweave/deadline/helm/deadline -f ~/Coreweave/deadline/helm/value-variants/$2/$2-setup.yaml -f ~/Coreweave/deadline/helm/value-variants/$2/$2-scale.yaml -f ~/Coreweave/deadline/helm/value-variants/$2/$2-workers.yaml --set mongodb.auth.rootPassword=$MONGODB_ROOT_PASSWORD --set mongodb.auth.replicaSetKey=$MONGODB_REPLICA_SET_KE
}
emc(){
  export MONGODB_REPLICA_SET_KEY=$(kubecolor get secret --namespace $1 $2-mongodb -o jsonpath="{.data.mongodb-replica-set-key}" | base64 --decode)
  export MONGODB_ROOT_PASSWORD=$(kubecolor get secret --namespace $1 $2-mongodb -o jsonpath="{.data.mongodb-root-password}" | base64 --decode)
}

alias bw-ssh-pw= "bw get password ssh-password| echo"

cm(){
  if ! (op account get > /dev/null);then 
  op signin
  fi
  chezmoi $@
}

klogin(){
  if ! (op account get > /dev/null);then 
  op signin
  fi
  python3 ~/.login/okta-login.py -u $(op item get coreweave.okta.com --fields username) -p $(op item get coreweave.okta.com --fields password) -c $(op item get coreweave.okta.com --fields client_id) -s $(op item get coreweave.okta.com --fields client_secret)
}

alias kaf="k apply -f"
alias kgs="k get service"
alias kgp="k get pod"
alias kubens="k ns"
alias kubectx="k ctx"
alias kvirt="k virt"
alias virtctl="k virt"
alias wk="watch kubectl get pods"
alias krrd="kubectl rollout restart deployment"

clone_block_volume() {
	if [ $# -lt 2 ]; then
		echo "Usage: $0 <source pvc> <destination pvc> <destination region> <namespace>"
		return 1
	fi
	if [ $# -lt 4 ]; then
		NS=$(kubectl get sa -o=jsonpath='{.items[0]..metadata.namespace}')
	else
		NS=$4
	fi

	SRC_PVC="$1"
	SRC_PVC_CLASS=$(kubectl -n ${NS} get pvc $SRC_PVC -o=jsonpath='{.spec.storageClassName}')
	SRC_PVC_SIZE=$(kubectl -n ${NS} get pvc $SRC_PVC -o=jsonpath='{.spec.resources.requests.storage}')
	SRC_PVC_REGION=${SRC_PVC_CLASS//*-}
	
	if [ $# -lt 3 ]; then
		DST_PVC_REGION=${SRC_PVC_REGION}
		DST_PVC_CLASS=${SRC_PVC_CLASS}
		DST_PVC="$2"
	else
		DST_PVC_REGION="$3"
		DST_PVC_CLASS="block-nvme-${DST_PVC_REGION}"
		DST_PVC="${2}-${3}"
	fi

	cat <<-EOF | kubectl -n ${NS} apply -f -
		{
		  "apiVersion": "v1",
		  "kind": "PersistentVolumeClaim",
		  "metadata": {
			"name": "${DST_PVC}"
		  },
		  "spec": {
			"accessModes": [
			  "ReadWriteOnce"
			],
			"storageClassName": "${DST_PVC_CLASS}",
			"volumeMode": "Block",
			"resources": {
			  "requests": {
				"storage": "${SRC_PVC_SIZE}"
			  }
			}
		  }
		}
	EOF
	
	KUBECTL_COMMAND_HEADERS=false kubectl -n ${NS} run clone --rm -ti --restart=Never --image=registry.gitlab.com/coreweave/admin-shell:7db3f7d7926938a5a2e624dbadef9440ae55fa69 --overrides="{
	  \"spec\": {
		\"tolerations\": [
		  {
			\"key\": \"node.coreweave.cloud/hypervisor\",
			\"operator\": \"Exists\"
		  },
		  {
			\"key\": \"is_cpu_compute\",
			\"operator\": \"Exists\"
		  }
		],
		\"nodeSelector\": {
		  \"node.coreweave.cloud/class\": \"cpu\",
		  \"ethernet.coreweave.cloud/speed\": \"10G\",
		  \"topology.kubernetes.io/region\": \"${SRC_PVC_REGION^^}\"
		},
		\"containers\": [
		  {
			\"name\": \"clone\",
			\"resources\": {
			  \"requests\": {
				\"cpu\": \"1\",
				\"memory\": \"2Gi\"
			  }
			},
			\"stdin\": true,
			\"tty\": true,
			\"stdinOnce\": true,
			\"image\": \"registry.gitlab.com/coreweave/admin-shell:7db3f7d7926938a5a2e624dbadef9440ae55fa69\",
			\"command\": [
			  \"sh\",
			  \"-c\",
			  \"dd if=/dev/xvda of=/dev/xvdb bs=1M status=progress\"
			],
			\"volumeDevices\": [
			  {
				\"devicePath\": \"/dev/xvda\",
				\"name\": \"source\"
			  },
			  {
				\"devicePath\": \"/dev/xvdb\",
				\"name\": \"dest\"
			  }
			]
		  }
		],
		\"volumes\": [
		  {
			\"name\": \"source\",
			\"persistentVolumeClaim\": {
			  \"claimName\": \"${SRC_PVC}\",
			  \"readOnly\": true
			}
		  },
		  {
			\"name\": \"dest\",
			\"persistentVolumeClaim\": {
			  \"claimName\": \"${DST_PVC}\",
			  \"readOnly\": false
			}
		  }
		]
	  }
	}"
}